train$sex<- factor(train$sex,
labels = c("female", "male"),
levels = c(0, 1))
postprun$finalModel
rpartpred4<-predict(postprun$finalModel, test, type='class')
train$sex<- factor(train$sex,
labels = c("female", "male"),
levels = c(0, 1))
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
train$survived
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 4,
trControl = ctrl,
metric = "ROC"))
6
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
#MaxDepth 으로 사전가지치기
train$survived<- factor(train$survived,
levels = c(0, 1),
labels = c("zero", "one"))
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
library(caret)
library(rpart)
library(rattle)
library(parallel)
library(rpart.plot)
df <- read.csv(file = "C:/Users/user/Desktop/3학년2학기/데이터사이언스/예습자료/2주/titanic3.csv",header=TRUE, fileEncoding = "UCS-2LE")
df <- data.frame(df$survived,df$pclass,df$age,df$sex,df$fare)
names(df)=c("survived","pclass","age","sex","fare")
df <- na.omit(df)
df
intrain<-createDataPartition(y=df$survived, p=0.7, list=FALSE)
train<-df[intrain, ]
test<-df[-intrain, ]
train
test
#MaxDepth 으로 사전가지치기
train$survived<- factor(train$survived,
levels = c(0, 1),
labels = c("zero", "one"))
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
plot(postprun)
fancyRpartPlot(postprun$finalModel)
confusionMatrix(postprun$finalModel)
rpartpred4<-predict(postprun$finalModel, test, type='class')
prefixmodel <- rpart(survived~pclass+age+sex+fare,data=train,max_depth = 6,method = "class")
prefixmodel <- rpart(survived~pclass+age+sex+fare,data=train,method = "class",control = rpart.control(maxdepth = 6))
fancyRpartPlot(prefixmodel)
rpartpred4<-predict(prefixmodel, test, type='class')
rpartpred4 <- as.factor(rpartpred4)
confusionMatrix(rpartpred4,survivpred)
survivpred <- as.factor(test$survived)
confusionMatrix(rpartpred4,survivpred)
df <- read.csv(file = "C:/Users/user/Desktop/3학년2학기/데이터사이언스/예습자료/2주/titanic3.csv",header=TRUE, fileEncoding = "UCS-2LE")
df <- data.frame(df$survived,df$pclass,df$age,df$sex,df$fare)
names(df)=c("survived","pclass","age","sex","fare")
df <- na.omit(df)
df
intrain<-createDataPartition(y=df$survived, p=0.7, list=FALSE)
train<-df[intrain, ]
test<-df[-intrain, ]
train
test
survivpred <- as.factor(test$survived)
fit <- rpart(survived~pclass+age+sex+fare,data=train,cp=-1,minsplit=2,minbucket=1,method = "class")
fancyRpartPlot(fit)
#일단 full tree에서의 정확도를 측정
rpartpred<-predict(fit, test, type='class')
rpartpred <- as.factor(rpartpred)
confusionMatrix(rpartpred,survivpred)
#여기는 cp최적화를 위한 그래프찍어봄
printcp(fit)
plotcp(fit)
#cp 중에 최적화된 값을 찾음
fit_prune1=prune(fit,cp=0.0014)
fancyRpartPlot(fit_prune1)
#cp 최적화 (사후가지치기)로 정확도 향상
rpartpred2<-predict(fit_prune1, test, type='class')
rpartpred2 <- as.factor(rpartpred2)
confusionMatrix(rpartpred2,survivpred)
#MaxDepth 으로 사전가지치기
train$survived<- factor(train$survived,
levels = c(0, 1),
labels = c("zero", "one"))
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
plot(postprun)
fancyRpartPlot(postprun$finalModel)
prefixmodel <- rpart(survived~pclass+age+sex+fare,data=train,method = "class",control = rpart.control(maxdepth = 7))
fancyRpartPlot(prefixmodel)
rpartpred4<-predict(prefixmodel, test, type='class')
rpartpred4 <- as.factor(rpartpred4)
confusionMatrix(rpartpred4,survivpred)
rtree_model <- rpart(survived~pclass+age+sex+fare,data=train,method = "class",control = rpart.control(maxdepth = 7))
rpartpred4<-predict(ftree_model, test, type='class')
rpartpred4<-predict(rtree_model, test, type='class')
rpartpred4 <- as.factor(rpartpred4)
confusionMatrix(rpartpred4,survivpred)
rtree_model2 <- rpart(survived~pclass+age+sex+fare, data=test, control=rpart.control(maxdepth=6))
rtree_model2
rpart.plot(rtree_model2)
rpart.rules(rtree_model2)
fancyRpartPlot(rtree_model2)
library(caret)
library(rpart)
library(rattle)
library(parallel)
library(rpart.plot)
df <- read.csv(file = "C:/Users/user/Desktop/3학년2학기/데이터사이언스/예습자료/2주/titanic3.csv",header=TRUE, fileEncoding = "UCS-2LE")
df <- data.frame(df$survived,df$pclass,df$age,df$sex,df$fare)
names(df)=c("survived","pclass","age","sex","fare")
df <- na.omit(df)
df
intrain<-createDataPartition(y=df$survived, p=0.7, list=FALSE)
train<-df[intrain, ]
test<-df[-intrain, ]
train
test
survivpred <- as.factor(test$survived)
fit <- rpart(survived~pclass+age+sex+fare,data=train,cp=-1,minsplit=2,minbucket=1,method = "class")
fancyRpartPlot(fit)
#일단 full tree에서의 정확도를 측정
rpartpred<-predict(fit, test, type='class')
rpartpred <- as.factor(rpartpred)
confusionMatrix(rpartpred,survivpred)
#여기는 cp최적화를 위한 그래프찍어봄
printcp(fit)
plotcp(fit)
#cp 중에 최적화된 값을 찾음
fit_prune1=prune(fit,cp=0.0014)
fancyRpartPlot(fit_prune1)
#cp 최적화 (사후가지치기)로 정확도 향상
rpartpred2<-predict(fit_prune1, test, type='class')
rpartpred2 <- as.factor(rpartpred2)
confusionMatrix(rpartpred2,survivpred)
#MaxDepth 으로 사전가지치기
train$survived<- factor(train$survived,
levels = c(0, 1),
labels = c("zero", "one"))
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
plot(postprun)
fancyRpartPlot(postprun$finalModel)
rtree_model <- rpart(survived~pclass+age+sex+fare,data=train,method = "class",control = rpart.control(maxdepth = 7))
rpartpred4<-predict(rtree_model, test, type='class')
rpartpred4 <- as.factor(rpartpred4)
confusionMatrix(rpartpred4,survivpred)
rtree_model2 <- rpart(survived~pclass+age+sex+fare, data=test, control=rpart.control(maxdepth=6))
rtree_model2
rpart.plot(rtree_model2)
rpart.rules(rtree_model2)
fancyRpartPlot(rtree_model2)
plot(postprun)
rpartpred5<-predict(postprun, test, type='class')
rpartpred5<-predict(postprun, test, type='raw')
rpartpred5 <- as.factor(rpartpred5)
confusionMatrix(rpartpred5,survivpred)
l
l
l
l
l
library(caret)
library(rpart)
library(rattle)
library(parallel)
library(rpart.plot)
confusionMatrix(rpartpred5,survivpred)
fancyRpartPlot(postprun)
rpartpred5<-predict(postprun, test, type='raw')
rpartpred5 <- as.factor(rpartpred5)
confusionMatrix(rpartpred5,survivpred)
#cp 최적화 (사후가지치기)로 정확도 향상
rpartpred2<-predict(fit_prune1, test, type='class')
rpartpred2 <- as.factor(rpartpred2)
confusionMatrix(rpartpred2,survivpred)
confusionMatrix(rpartpred4,survivpred)
rpartpred5<-predict(postprun, test, type='prob')
rpartpred5 <- as.factor(rpartpred5)
confusionMatrix(rpartpred5,survivpred)
rpartpred5<-predict(postprun, test, type='class')
rpartpred5<-predict(postprun, test, type='raw')
rpartpred5 <- as.factor(rpartpred5)
confusionMatrix(rpartpred5,survivpred)
library(caret)
library(rpart)
library(rattle)
library(parallel)
library(rpart.plot)
df <- read.csv(file = "C:/Users/user/Desktop/3학년2학기/데이터사이언스/예습자료/2주/titanic3.csv",header=TRUE, fileEncoding = "UCS-2LE")
df <- data.frame(df$survived,df$pclass,df$age,df$sex,df$fare)
names(df)=c("survived","pclass","age","sex","fare")
df <- na.omit(df)
df
intrain<-createDataPartition(y=df$survived, p=0.7, list=FALSE)
train<-df[intrain, ]
test<-df[-intrain, ]
train
test
survivpred <- as.factor(test$survived)
#MaxDepth 으로 사전가지치기
train$survived<- factor(train$survived,
levels = c(0, 1),
labels = c("zero", "one"))
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
plot(postprun)
fancyRpartPlot(postprun$finalModel)
rtree_model <- rpart(survived~pclass+age+sex+fare,data=train,method = "class",control = rpart.control(maxdepth = 7))
rpartpred4<-predict(rtree_model, test, type='class')
rpartpred4 <- as.factor(rpartpred4)
confusionMatrix(rpartpred4,survivpred)
confusionMatrix(rpartpred5,reference=train$survived,survivpred)
rpartpred5<-predict(postprun, test, type='raw')
rpartpred5 <- as.factor(rpartpred5)
confusionMatrix(rpartpred5,reference=train$survived,survivpred)
confusionMatrix(rpartpred5,reference=train$survived,positive = 'yes')
confusionMatrix(rpartpred5,reference=train$survived)
confusionMatrix(rpartpred5,reference=survivpred)
confusionMatrix(rpartpred5,reference=survived)
confusionMatrix(rpartpred5,reference=df$survived)
confusionMatrix(rpartpred5,test$survived)
survivpred <- as.factor(test$survived)
confusionMatrix(rpartpred5,survivpred)
library(caret)
library(rpart)
library(rattle)
library(parallel)
library(rpart.plot)
df <- read.csv(file = "C:/Users/user/Desktop/3학년2학기/데이터사이언스/예습자료/2주/titanic3.csv",header=TRUE, fileEncoding = "UCS-2LE")
df <- data.frame(df$survived,df$pclass,df$age,df$sex,df$fare)
names(df)=c("survived","pclass","age","sex","fare")
df <- na.omit(df)
df
intrain<-createDataPartition(y=df$survived, p=0.7, list=FALSE)
train<-df[intrain, ]
test<-df[-intrain, ]
train
test
survivpred <- as.factor(test$survived)
fit <- rpart(survived~pclass+age+sex+fare,data=train,cp=-1,minsplit=2,minbucket=1,method = "class")
fancyRpartPlot(fit)
#일단 full tree에서의 정확도를 측정
rpartpred<-predict(fit, test, type='class')
rpartpred <- as.factor(rpartpred)
confusionMatrix(rpartpred,survivpred)
#여기는 cp최적화를 위한 그래프찍어봄
printcp(fit)
plotcp(fit)
#cp 중에 최적화된 값을 찾음
fit_prune1=prune(fit,cp=0.0014)
fancyRpartPlot(fit_prune1)
#cp 최적화 (사후가지치기)로 정확도 향상
rpartpred2<-predict(fit_prune1, test, type='class')
rpartpred2 <- as.factor(rpartpred2)
confusionMatrix(rpartpred2,survivpred)
#MaxDepth 으로 사전가지치기
train$survived<- factor(train$survived,
levels = c(0, 1),
labels = c("zero", "one"))
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
plot(postprun)
fancyRpartPlot(postprun$finalModel)
rtree_model <- rpart(survived~pclass+age+sex+fare,data=train,method = "class",control = rpart.control(maxdepth = 7))
rpartpred4<-predict(rtree_model, test, type='class')
rpartpred4 <- as.factor(rpartpred4)
confusionMatrix(rpartpred4,survivpred)
rpartpred5<-predict(postprun, test, type='raw')
rpartpred5 <- as.factor(rpartpred5)
confusionMatrix(rpartpred5,survivpred)
library(caret)
library(rpart)
library(rattle)
library(parallel)
library(rpart.plot)
df <- read.csv(file = "C:/Users/user/Desktop/3학년2학기/데이터사이언스/예습자료/2주/titanic3.csv",header=TRUE, fileEncoding = "UCS-2LE")
df <- data.frame(df$survived,df$pclass,df$age,df$sex,df$fare)
names(df)=c("survived","pclass","age","sex","fare")
df <- na.omit(df)
df
intrain<-createDataPartition(y=df$survived, p=0.7, list=FALSE)
train<-df[intrain, ]
test<-df[-intrain, ]
train
test
fit <- rpart(survived~pclass+age+sex+fare,data=train,cp=-1,minsplit=2,minbucket=1,method = "class")
fancyRpartPlot(fit)
#일단 full tree에서의 정확도를 측정
rpartpred<-predict(fit, test, type='class')
rpartpred <- as.factor(rpartpred)
confusionMatrix(rpartpred,survivpred)
confusionMatrix(rpartpred,df$survived)
confusionMatrix(rpartpred,as.factor(df$survived))
confusionMatrix(rpartpred,reference = df$survived)
confusionMatrix(rpartpred,reference = df$survived,positive = "yes")
confusionMatrix(rpartpred,reference = df$survived,positive = "1")
confusionMatrix(rpartpred,reference = df$survived,positive = 1)
View(df)
confusionMatrix(rpartpred,reference = df$survived,positive = '1')
confusionMatrix(rpartpred,reference = test$survived,positive = '1')
confusionMatrix(rpartpred,reference = train$survived,positive = '1')
#==================================================================
rpartpred5<-predict(postprun, test, type='raw')
rpartpred5 <- as.factor(rpartpred5)
confusionMatrix(rpartpred5,survivpred)
library(caret)
library(rpart)
library(rattle)
library(parallel)
library(rpart.plot)
confusionMatrix(rpartpred5,survivpred)
confusionMatrix(rpartpred5,survivpred,positive = "one")
rtree_model <- rpart(survived~pclass+age+sex+fare,data=train,method = "class",control = rpart.control(maxdepth = 7))
rpartpred4<-predict(rtree_model, test, type='class')
rpartpred4 <- as.factor(rpartpred4)
confusionMatrix(rpartpred4,survivpred)
confusionMatrix(rpartpred4,survivpred,positive = "one")
rtree_model <- rpart(survived~pclass+age+sex+fare,data=train,method = "class",control = rpart.control(maxdepth = 7))
rpartpred4<-predict(rtree_model, test, type='class')
rpartpre4 <- as.factor(rpartpre4)
confusionMatrix(rpartpre4,survivpred)
rpartpre4 <- as.factor(rpartpred4)
confusionMatrix(rpartpred4,survivpred)
#일단 full tree에서의 정확도를 측정
#==================================================================
rpartpred<-predict(fit, test, type='class')
rpartpred <- as.factor(rpartpred)
confusionMatrix(rpartpred,survivpred)
library(caret)
library(rpart)
library(rattle)
library(parallel)
library(rpart.plot)
df <- read.csv(file = "C:/Users/user/Desktop/3학년2학기/데이터사이언스/예습자료/2주/titanic3.csv",header=TRUE, fileEncoding = "UCS-2LE")
df <- data.frame(df$survived,df$pclass,df$age,df$sex,df$fare)
names(df)=c("survived","pclass","age","sex","fare")
df <- na.omit(df)
df
intrain<-createDataPartition(y=df$survived, p=0.7, list=FALSE)
train<-df[intrain, ]
test<-df[-intrain, ]
train
test
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
#==================================================================
#MaxDepth 으로 사전가지치기
train$survived<- factor(train$survived,
levels = c(0, 1),
labels = c("zero", "one"))
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
plot(postprun)
fancyRpartPlot(postprun$finalModel)
#==================================================================
rpartpred5<-predict(postprun, test, type='raw')
rpartpred5 <- as.factor(rpartpred5)
confusionMatrix(rpartpred5,survivpred,positive = "one")
confusionMatrix(rpartpred5,survivpred,positive = "zero")
#==================================================================
survivpred <- as.factor(test$survived)
confusionMatrix(rpartpred5,survivpred,positive = "zero")
confusionMatrix(rpartpred5,df$survived,positive = "zero")
library(caret)
library(rpart)
library(rattle)
library(parallel)
library(rpart.plot)
df <- read.csv(file = "C:/Users/user/Desktop/3학년2학기/데이터사이언스/예습자료/2주/titanic3.csv",header=TRUE, fileEncoding = "UCS-2LE")
df <- data.frame(df$survived,df$pclass,df$age,df$sex,df$fare)
names(df)=c("survived","pclass","age","sex","fare")
df <- na.omit(df)
df
intrain<-createDataPartition(y=df$survived, p=0.7, list=FALSE)
train<-df[intrain, ]
test<-df[-intrain, ]
train
test
#==================================================================
survivpred <- as.factor(test$survived)
#==================================================================
rtree_model2 <- rpart(survived~pclass+age+sex+fare, data=test, control=rpart.control(maxdepth=6))
rtree_model2
rpart.plot(rtree_model2)
rpart.rules(rtree_model2)
fancyRpartPlot(rtree_model2)
#==================================================================
#MaxDepth 으로 사전가지치기
train$survived<- factor(train$survived,
levels = c(0, 1),
labels = c("zero", "one"))
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
plot(postprun)
fancyRpartPlot(postprun$finalModel)
#==================================================================
rtree_model2 <- rpart(survived~pclass+age+sex+fare, data=test, control=rpart.control(maxdepth=8))
rtree_model2
rpart.plot(rtree_model2)
rpart.rules(rtree_model2)
fancyRpartPlot(rtree_model2)
library(caret)
library(rpart)
library(rattle)
library(parallel)
library(rpart.plot)
df <- read.csv(file = "C:/Users/user/Desktop/3학년2학기/데이터사이언스/예습자료/2주/titanic3.csv",header=TRUE, fileEncoding = "UCS-2LE")
df <- data.frame(df$survived,df$pclass,df$age,df$sex,df$fare)
names(df)=c("survived","pclass","age","sex","fare")
df <- na.omit(df)
df
intrain<-createDataPartition(y=df$survived, p=0.7, list=FALSE)
train<-df[intrain, ]
test<-df[-intrain, ]
train
test
#==================================================================
survivpred <- as.factor(test$survived)
#==================================================================
#MaxDepth 으로 사전가지치기
train$survived<- factor(train$survived,
levels = c(0, 1),
labels = c("zero", "one"))
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
system.time (postprun <- train(survived~., data=train,
method = "rpart2",
tuneLength = 6,
trControl = ctrl,
metric = "ROC"))
plot(postprun)
fancyRpartPlot(postprun$finalModel)
rtree_model <- rpart(survived~pclass+age+sex+fare,data=train,method = "class",control = rpart.control(maxdepth = 7))
#==================================================================
rtree_model2 <- rpart(survived~pclass+age+sex+fare, data=test, control=rpart.control(maxdepth=6))
rtree_model2
rpart.plot(rtree_model2)
rpart.rules(rtree_model2)
fancyRpartPlot(rtree_model2)
